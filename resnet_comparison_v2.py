# -*- coding: utf-8 -*-
"""Resnet_Comparison_v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lmV5qhKK2pVSLnxfph7SIQ5n_Irs_Lvj
"""

print("started")
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torchvision.models import resnet50
from torchvision.models import resnet18
from torchvision.datasets import CIFAR100
from sklearn.metrics import precision_recall_fscore_support
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, random_split

# Define the transformation for data preprocessing
transform_train = transforms.Compose(
    [
        transforms.RandomHorizontalFlip(),
        transforms.RandomCrop(32, padding=4),
        transforms.RandomRotation(15),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ]
)

transform_test = transforms.Compose(
    [
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ]
)

# Load CIFAR-10 dataset
# Load the datasets
dataset_train = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True, transform=transform_train
)

dataset_test = torchvision.datasets.CIFAR10(
    root='./data', train=False, download=True, transform=transform_test
)

# Split the dataset into training and validation sets
train_size = int(0.8 * len(dataset_train))
val_size = len(dataset_train) - train_size
train_dataset, val_dataset = random_split(dataset_train, [train_size, val_size])

# Create the DataLoaders
trainloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=128, shuffle=True, num_workers=2
)

val_loader = torch.utils.data.DataLoader(
    val_dataset, batch_size=128, shuffle=False, num_workers=2
)

testloader = torch.utils.data.DataLoader(
    dataset_test, batch_size=128, shuffle=False, num_workers=2
)

# Load ResNet-50 model
model = resnet50(pretrained=False, num_classes=10)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=5e-4)
scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1)

# Move model to GPU if available
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

# Set patience level and initial values for best loss and patience counter
patience = 20
best_val_loss = float('inf')
patience_counter = 0

# Training loop
num_epochs = 200
for epoch in range(num_epochs):
    model.train()
    train_loss = 0.0
    correct = 0
    total = 0

    for batch_idx, (inputs, targets) in enumerate(trainloader):
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()
    model.eval()
    with torch.no_grad():
        val_loss = 0
        for batch_idx, (inputs, targets) in enumerate(val_loader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            val_loss += loss.item()
    val_loss = val_loss / len(val_loader)

    # Check if the validation loss improved
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model's state
        patience_counter = 0  # Reset the patience counter
    else:
        patience_counter += 1  # Increment the patience counter

    # Early stopping
    if patience_counter >= patience:
        print("Early stopping triggered. Stopping training.")
        break
    # Update learning rate
    scheduler.step()

    # Print training progress
    print(
        f"Epoch [{epoch + 1}/{num_epochs}] Loss: {train_loss / (batch_idx + 1):.4f} "
        f"Acc: {100.0 * correct / total:.2f}%"
    )

# Evaluate on test set
model.eval()
test_loss = 0.0
correct = 0
total = 0

with torch.no_grad():
    for batch_idx, (inputs, targets) in enumerate(testloader):
        inputs, targets = inputs.to(device), targets.to(device)
        outputs = model(inputs)
        loss = criterion(outputs, targets)

        test_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()
#Print test set accuracy
print(f"Test set: Average loss: {test_loss / (batch_idx + 1):.4f}, Accuracy: {100.0 * correct / total:.2f}%")

torch.save(model.state_dict(), "resnet50_weights.pth")

# Load the CIFAR-100 datasets
trainset_cifar100  = CIFAR100(
    root='./data', train=True, download=True, transform=transform_train
)

testset_cifar100  = CIFAR100(
    root='./data', train=False, download=True, transform=transform_test
)

# Split the CIFAR-100 dataset into training and validation sets
train_size_cifar100 = int(0.8 * len(trainset_cifar100 ))
val_size_cifar100 = len(trainset_cifar100 ) - train_size_cifar100
train_dataset_cifar100, val_dataset_cifar100 = random_split(trainset_cifar100 , [train_size_cifar100, val_size_cifar100])

# Create the DataLoaders for CIFAR-100
trainloader_cifar100 = torch.utils.data.DataLoader(
    train_dataset_cifar100, batch_size=128, shuffle=True, num_workers=2
)

val_loader_cifar100 = torch.utils.data.DataLoader(
    val_dataset_cifar100, batch_size=128, shuffle=False, num_workers=2
)

testloader_cifar100 = torch.utils.data.DataLoader(
    testset_cifar100 , batch_size=128, shuffle=False, num_workers=2
)

# Shrink ResNet-50 to ResNet-18
model.load_state_dict(torch.load('resnet50_weights.pth'))

# Create a new ResNet-18 model
resnet18_model = resnet18(pretrained=False, num_classes=100)

# Copy the weights of the common layers
resnet18_state_dict = resnet18_model.state_dict()
resnet50_state_dict = model.state_dict()

for resnet18_key, resnet50_key in zip(resnet18_state_dict.keys(), resnet50_state_dict.keys()):
    if resnet18_state_dict[resnet18_key].shape == resnet50_state_dict[resnet50_key].shape:
        resnet18_state_dict[resnet18_key].data.copy_(resnet50_state_dict[resnet50_key].data)

resnet18_model.load_state_dict(resnet18_state_dict)

# Initialize the weights of the remaining layers
for m in resnet18_model.modules():
    if isinstance(m, nn.Conv2d):
        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
    elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)

# Move the model to the device
resnet18_model.to(device)

def create_few_shot_dataloader(dataset, k_shot, batch_size=128, num_workers=2):
    labels = [sample[1] for sample in dataset]
    unique_labels = set(labels)
    few_shot_indices = []

    for label in unique_labels:
        label_indices = [i for i, x in enumerate(labels) if x == label]
        chosen_indices = np.random.choice(label_indices, k_shot, replace=False)
        few_shot_indices.extend(chosen_indices)

    few_shot_sampler = torch.utils.data.SubsetRandomSampler(few_shot_indices)
    few_shot_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=few_shot_sampler, num_workers=num_workers)

    return few_shot_dataloader

k_shot = 5  # Number of samples per class for few-shot learning
few_shot_trainloader_cifar100 = create_few_shot_dataloader(trainset_cifar100, k_shot)


# Fine-tune ResNet-18 on CIFAR-100
optimizer_ft = optim.SGD(resnet18_model.parameters(), lr=0.01, weight_decay=5e-4)
scheduler_ft = optim.lr_scheduler.MultiStepLR(optimizer_ft, milestones=[100, 150], gamma=0.1)

# Set patience level and initial values for best loss and patience counter
patience = 25
best_val_loss = float('inf')
patience_counter = 0

# Fine-tune ResNet-18 on CIFAR-100 with few-shot learning
for epoch in range(num_epochs):
    resnet18_model.train()
    train_loss = 0.0
    correct = 0
    total = 0
    for batch_idx, (inputs, targets) in enumerate(few_shot_trainloader_cifar100):
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer_ft.zero_grad()
        outputs = resnet18_model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer_ft.step()

        train_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()
    model.eval()
    with torch.no_grad():
        val_loss = 0
        for batch_idx, (inputs, targets) in enumerate(val_loader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            val_loss += loss.item()
    val_loss = val_loss / len(val_loader)

    # Check if the validation loss improved
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model's state
        patience_counter = 0  # Reset the patience counter
    else:
        patience_counter += 1  # Increment the patience counter

    # Early stopping
    if patience_counter >= patience:
        print("Early stopping triggered. Stopping training.")
        break
    # Update learning rate
    scheduler.step()

    # Print training progress
    print(
        f"Epoch [{epoch + 1}/{num_epochs}] Loss: {train_loss / (batch_idx + 1):.4f} "
        f"Acc: {100.0 * correct / total:.2f}%"
    )

# Train a new ResNet-18 from scratch on CIFAR-100
resnet18_scratch = resnet18(pretrained=False, num_classes=100).to(device)
optimizer_scratch = optim.SGD(resnet18_scratch.parameters(), lr=0.01, weight_decay=5e-4)
scheduler_scratch = optim.lr_scheduler.MultiStepLR(optimizer_scratch, milestones=[100, 150], gamma=0.1)

patience = 35
best_val_loss = float('inf')
patience_counter = 0
print("Training ResNet-18 from scratch on CIFAR-100:")
for epoch in range(num_epochs):
    resnet18_scratch.train()
    train_loss = 0.0
    correct = 0
    total = 0
    for batch_idx, (inputs, targets) in enumerate(trainloader_cifar100):
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer_scratch.zero_grad()
        outputs = resnet18_scratch(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer_scratch.step()

        train_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()
     # Validation loop
    model.eval()
    with torch.no_grad():
        val_loss = 0
        for batch_idx, (inputs, targets) in enumerate(val_loader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            val_loss += loss.item()

    # Calculate the average validation loss for this epoch
    val_loss = val_loss / len(val_loader)

    # Check if the validation loss improved
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model's state
        patience_counter = 0  # Reset the patience counter
    else:
        patience_counter += 1  # Increment the patience counter

    # Early stopping
    if patience_counter >= patience:
        print("Early stopping triggered. Stopping training.")
        break
    scheduler_scratch.step()

    print(f"Epoch [{epoch + 1}/{num_epochs}] Loss: {train_loss / (batch_idx + 1):.4f} Acc: {100.0 * correct / total:.2f}%")

# Evaluate the fine-tuned ResNet-18 model on the CIFAR-100 test set
resnet18_model.eval()
test_loss = 0.0
correct = 0
total = 0

with torch.no_grad():
    for batch_idx, (inputs, targets) in enumerate(testloader_cifar100):
        inputs, targets = inputs.to(device), targets.to(device)
        outputs = resnet18_model(inputs)
        loss = criterion(outputs, targets)

        test_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()

print(f"Fine-tuned ResNet-18: Test set: Average loss: {test_loss / (batch_idx + 1):.4f}, Accuracy: {100.0 * correct / total:.2f}%")

# Evaluate the ResNet-18 model trained from scratch on the CIFAR-100 test set
resnet18_scratch.eval()
test_loss = 0.0
correct = 0
total = 0

with torch.no_grad():
    for batch_idx, (inputs, targets) in enumerate(testloader_cifar100):
        inputs, targets = inputs.to(device), targets.to(device)
        outputs = resnet18_scratch(inputs)
        loss = criterion(outputs, targets)

        test_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()

print(f"ResNet-18 from scratch: Test set: Average loss: {test_loss / (batch_idx + 1):.4f}, Accuracy: {100.0 * correct / total:.2f}%")

def evaluate_model(model, dataloader):
    model.eval()
    all_targets = []
    all_predictions = []

    with torch.no_grad():
        for inputs, targets in dataloader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            _, predicted = outputs.max(1)

            all_targets.extend(targets.cpu().numpy())
            all_predictions.extend(predicted.cpu().numpy())

    return precision_recall_fscore_support(all_targets, all_predictions, average=None)

# Evaluate fine-tuned ResNet-18
precision_ft, recall_ft, f1_score_ft, _ = evaluate_model(resnet18_model, testloader_cifar100)

# Evaluate ResNet-18 trained from scratch
precision_scratch, recall_scratch, f1_score_scratch, _ = evaluate_model(resnet18_scratch, testloader_cifar100)

# Print results
print("Class | Fine-tuned | From scratch")
print("------+------------+-------------")
for i in range(len(precision_ft)):
    print(f"{i:4d} | {f1_score_ft[i]:.4f}    | {f1_score_scratch[i]:.4f}")

patience = 35
best_val_loss = float('inf')
patience_counter = 0

# Function to train and evaluate a model
def train_and_evaluate(model, trainloader, testloader, optimizer, scheduler, num_epochs):
    train_losses = []
    train_accuracies = []
    test_accuracies = []

    for epoch in range(num_epochs):
        model.train()
        train_loss = 0.0
        correct = 0
        total = 0
        for batch_idx, (inputs, targets) in enumerate(trainloader):
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
         # Validation loop
        model.eval()
        with torch.no_grad():
            val_loss = 0
            for batch_idx, (inputs, targets) in enumerate(val_loader):
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                val_loss += loss.item()

        # Calculate the average validation loss for this epoch
        val_loss = val_loss / len(val_loader)

        # Check if the validation loss improved
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), 'best_model.pth')  # Save the best model's state
            patience_counter = 0  # Reset the patience counter
        else:
            patience_counter += 1  # Increment the patience counter

        # Early stopping
        if patience_counter >= patience:
            print("Early stopping triggered. Stopping training.")
            break
        scheduler.step()
        train_losses.append(train_loss / (batch_idx + 1))
        train_accuracies.append(100.0 * correct / total)

        test_acc = evaluate_accuracy(model, testloader)
        test_accuracies.append(test_acc)

    return train_losses, train_accuracies, test_accuracies

# Function to evaluate the accuracy of a model
def evaluate_accuracy(model, dataloader):
    model.eval()
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, targets in dataloader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

    return 100.0 * correct / total

# Train and evaluate both models
train_losses_ft, train_accuracies_ft, test_accuracies_ft = train_and_evaluate(resnet18_model, trainloader_cifar100, testloader_cifar100, optimizer_ft, scheduler_ft, num_epochs)
train_losses_scratch, train_accuracies_scratch, test_accuracies_scratch = train_and_evaluate(resnet18_scratch, trainloader_cifar100, testloader_cifar100, optimizer_scratch, scheduler_scratch, num_epochs)

# Save training loss plot
print("training_loss_comparison.png")
plt.figure()
plt.plot(train_losses_ft, label='Fine-tuned ResNet-18')
plt.plot(train_losses_scratch, label='ResNet-18 from scratch')
plt.xlabel('Epoch')
plt.ylabel('Training Loss')
plt.legend()
plt.title("Training Loss Comparison")
plt.savefig('training_loss_comparison1.png')
plt.close()
# Save training accuracy plot
print('training_accuracy_comparison.png')
plt.figure()
plt.plot(train_accuracies_ft, label='Fine-tuned ResNet-18')
plt.plot(train_accuracies_scratch, label='ResNet-18 from scratch')
plt.xlabel('Epoch')
plt.ylabel('Training Accuracy')
plt.legend()
plt.title("Training Accuracy Comparison")
plt.savefig('training_accuracy_comparison1.png')
plt.close()
# Save test accuracy plot
print("test")
plt.figure()
plt.plot(test_accuracies_ft, label='Fine-tuned ResNet-18')
plt.plot(test_accuracies_scratch, label='ResNet-18 from scratch')
plt.xlabel('Epoch')
plt.ylabel('Test Accuracy')
plt.legend()
plt.title("Test Accuracy Comparison")
plt.savefig('test_accuracy_comparison1.png')
plt.close()